# arXiv Paper Digest - 2026-01-26

*Generated on 2026-01-26 09:35:34*

Found 10 relevant papers.

---

## 1. [Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators](http://arxiv.org/abs/2601.16866v1)

**Authors:** Lucía Güitta-López, Vincenzo Suriani, Jaime Boal, Álvaro J. López-López, Daniele Nardi

**Published:** 2026-01-23

**Categories:** cs.RO, cs.AI

**Relevance Score:** 0.669
 (Keyword matches: 2)

**Topic:** Robotics Manipulation

**Abstract:** Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational a...

[PDF](https://arxiv.org/pdf/2601.16866v1) | [arXiv](http://arxiv.org/abs/2601.16866v1)

---

## 2. [Point Bridge: 3D Representations for Cross Domain Policy Learning](http://arxiv.org/abs/2601.16212v1)

**Authors:** Siddhant Haldar, Lars Johannsmeier, Lerrel Pinto, Abhishek Gupta, Dieter Fox, et al. (+2 more)

**Published:** 2026-01-22

**Categories:** cs.RO

**Relevance Score:** 0.655

**Topic:** Robotics Manipulation

**Abstract:** Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by th...

[PDF](https://arxiv.org/pdf/2601.16212v1) | [arXiv](http://arxiv.org/abs/2601.16212v1)

---

## 3. [CADGrasp: Learning Contact and Collision Aware General Dexterous Grasping in Cluttered Scenes](http://arxiv.org/abs/2601.15039v1)

**Authors:** Jiyao Zhang, Zhiyuan Ma, Tianhao Wu, Zeyuan Chen, Hao Dong

**Published:** 2026-01-21

**Categories:** cs.RO

**Relevance Score:** 0.641
 (Keyword matches: 2)

**Topic:** Robotics Manipulation

**Abstract:** Dexterous grasping in cluttered environments presents substantial challenges due to the high degrees of freedom of dexterous hands, occlusion, and potential collisions arising from diverse object geometries and complex layouts. To address these challenges, we propose CADGrasp, a two-stage algorithm ...

[PDF](https://arxiv.org/pdf/2601.15039v1) | [arXiv](http://arxiv.org/abs/2601.15039v1)

---

## 4. [DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning](http://arxiv.org/abs/2601.16046v1)

**Authors:** Junha Lee, Eunha Park, Minsu Cho

**Published:** 2026-01-22

**Categories:** cs.RO, cs.CV

**Relevance Score:** 0.613
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reaso...

[PDF](https://arxiv.org/pdf/2601.16046v1) | [arXiv](http://arxiv.org/abs/2601.16046v1)

---

## 5. [IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance](http://arxiv.org/abs/2601.16207v1)

**Authors:** Jongwoo Park, Kanchana Ranasinghe, Jinhyeok Jang, Cristina Mata, Yoo Sung Jang, et al. (+1 more)

**Published:** 2026-01-22

**Categories:** cs.RO

**Relevance Score:** 0.605

**Topic:** Robotics Manipulation

**Abstract:** Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the mod...

[PDF](https://arxiv.org/pdf/2601.16207v1) | [arXiv](http://arxiv.org/abs/2601.16207v1)

---

## 6. [A Mobile Magnetic Manipulation Platform for Gastrointestinal Navigation with Deep Reinforcement Learning Control](http://arxiv.org/abs/2601.15545v1)

**Authors:** Zhifan Yan, Chang Liu, Yiyang Jiang, Wenxuan Zheng, Xinhao Chen, et al. (+1 more)

**Published:** 2026-01-22

**Categories:** cs.RO

**Relevance Score:** 0.604
 (Keyword matches: 3)

**Topic:** Robotics Manipulation

**Abstract:** Targeted drug delivery in the gastrointestinal (GI) tract using magnetic robots offers a promising alternative to systemic treatments. However, controlling these robots is a major challenge. Stationary magnetic systems have a limited workspace, while mobile systems (e.g., coils on a robotic arm) suf...

[PDF](https://arxiv.org/pdf/2601.15545v1) | [arXiv](http://arxiv.org/abs/2601.15545v1)

---

## 7. [CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation](http://arxiv.org/abs/2601.15541v1)

**Authors:** Heng Zhang, Wei-Hsing Huang, Qiyi Tong, Gokhan Solak, Puze Liu, et al. (+3 more)

**Published:** 2026-01-21

**Categories:** cs.RO

**Relevance Score:** 0.588
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (...

[PDF](https://arxiv.org/pdf/2601.15541v1) | [arXiv](http://arxiv.org/abs/2601.15541v1)

---

## 8. [A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint](http://arxiv.org/abs/2601.13639v1)

**Authors:** Deyun Qin, Zezhi Liu, Hanqian Luo, Xiao Liang, Yongchun Fang

**Published:** 2026-01-20

**Categories:** cs.RO

**Relevance Score:** 0.580
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Active perception in vision-based robotic manipulation aims to move the camera toward more informative observation viewpoints, thereby providing high-quality perceptual inputs for downstream tasks. Most existing active perception methods rely on iterative optimization, leading to high time and motio...

[PDF](https://arxiv.org/pdf/2601.13639v1) | [arXiv](http://arxiv.org/abs/2601.13639v1)

---

## 9. [DroneVLA: VLA based Aerial Manipulation](http://arxiv.org/abs/2601.13809v2)

**Authors:** Fawad Mehboob, Monijesu James, Amir Habel, Jeffrin Sam, Miguel Altamirano Cabrera, et al. (+1 more)

**Published:** 2026-01-20

**Categories:** cs.RO, cs.AI

**Relevance Score:** 0.570
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting h...

[PDF](https://arxiv.org/pdf/2601.13809v2) | [arXiv](http://arxiv.org/abs/2601.13809v2)

---

## 10. [HumanoidVLM: Vision-Language-Guided Impedance Control for Contact-Rich Humanoid Manipulation](http://arxiv.org/abs/2601.14874v1)

**Authors:** Yara Mahmoud, Yasheerah Yaqoot, Miguel Altamirano Cabrera, Dzmitry Tsetserukou

**Published:** 2026-01-21

**Categories:** cs.RO

**Relevance Score:** 0.570
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Humanoid robots must adapt their contact behavior to diverse objects and tasks, yet most controllers rely on fixed, hand-tuned impedance gains and gripper settings. This paper introduces HumanoidVLM, a vision-language driven retrieval framework that enables the Unitree G1 humanoid to select task-app...

[PDF](https://arxiv.org/pdf/2601.14874v1) | [arXiv](http://arxiv.org/abs/2601.14874v1)

---
