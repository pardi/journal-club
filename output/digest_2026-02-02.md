# arXiv Paper Digest - 2026-02-02

*Generated on 2026-02-02 09:48:49*

Found 10 relevant papers.

---

## 1. [Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation](http://arxiv.org/abs/2601.22988v1)

**Authors:** Di Zhang, Weicheng Duan, Dasen Gu, Hongye Lu, Hai Zhang, et al. (+3 more)

**Published:** 2026-01-30

**Categories:** cs.RO

**Relevance Score:** 0.716
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Real-world robotic manipulation demands visuomotor policies capable of robust spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including...

[PDF](https://arxiv.org/pdf/2601.22988v1) | [arXiv](http://arxiv.org/abs/2601.22988v1)

---

## 2. [Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation](http://arxiv.org/abs/2601.23087v1)

**Authors:** Wu Songwei, Jiang Zhiduo, Xie Guanghu, Liu Yang, Liu Hong

**Published:** 2026-01-30

**Categories:** cs.RO

**Relevance Score:** 0.681
 (Keyword matches: 2)

**Topic:** Robotics Manipulation

**Abstract:** Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference la...

[PDF](https://arxiv.org/pdf/2601.23087v1) | [arXiv](http://arxiv.org/abs/2601.23087v1)

---

## 3. [MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts](http://arxiv.org/abs/2601.21971v1)

**Authors:** Lorenzo Mazza, Ariel Rodriguez, Rayan Younis, Martin Lelis, Ortrun Hellig, et al. (+4 more)

**Published:** 2026-01-29

**Categories:** cs.RO, cs.AI, cs.LG

**Relevance Score:** 0.658
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Imitation learning has achieved remarkable success in robotic manipulation, yet its application to surgical robotics remains challenging due to data scarcity, constrained workspaces, and the need for an exceptional level of safety and predictability. We present a supervised Mixture-of-Experts (MoE) ...

[PDF](https://arxiv.org/pdf/2601.21971v1) | [arXiv](http://arxiv.org/abs/2601.21971v1)

---

## 4. [mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning](http://arxiv.org/abs/2601.22074v1)

**Authors:** Kevin Zakka, Qiayuan Liao, Brent Yi, Louis Le Lay, Koushil Sreenath, et al. (+1 more)

**Published:** 2026-01-29

**Categories:** cs.RO

**Relevance Score:** 0.616

**Topic:** Robotics Manipulation

**Abstract:** We present mjlab, a lightweight, open-source framework for robot learning that combines GPU-accelerated simulation with composable environments and minimal setup friction. mjlab adopts the manager-based API introduced by Isaac Lab, where users compose modular building blocks for observations, reward...

[PDF](https://arxiv.org/pdf/2601.22074v1) | [arXiv](http://arxiv.org/abs/2601.22074v1)

---

## 5. [Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations](http://arxiv.org/abs/2601.21713v1)

**Authors:** Donatien Delehelle, Fei Chen, Darwin Caldwell

**Published:** 2026-01-29

**Categories:** cs.RO, cs.AI

**Relevance Score:** 0.608
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Cloth manipulation is a ubiquitous task in everyday life, but it remains an open challenge for robotics. The difficulties in developing cloth manipulation policies are attributed to the high-dimensional state space, complex dynamics, and high propensity to self-occlusion exhibited by fabrics. As ana...

[PDF](https://arxiv.org/pdf/2601.21713v1) | [arXiv](http://arxiv.org/abs/2601.21713v1)

---

## 6. [AIR-VLA: Vision-Language-Action Systems for Aerial Manipulation](http://arxiv.org/abs/2601.21602v1)

**Authors:** Jianli Sun, Bin Tian, Qiyao Zhang, Chengxiang Li, Zihan Song, et al. (+3 more)

**Published:** 2026-01-29

**Categories:** cs.RO

**Relevance Score:** 0.600
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** While Vision-Language-Action (VLA) models have achieved remarkable success in ground-based embodied intelligence, their application to Aerial Manipulation Systems (AMS) remains a largely unexplored frontier. The inherent characteristics of AMS, including floating-base dynamics, strong coupling betwe...

[PDF](https://arxiv.org/pdf/2601.21602v1) | [arXiv](http://arxiv.org/abs/2601.21602v1)

---

## 7. [Towards Space-Based Environmentally-Adaptive Grasping](http://arxiv.org/abs/2601.21394v1)

**Authors:** Leonidas Askianakis, Aleksandr Artemov

**Published:** 2026-01-29

**Categories:** cs.RO

**Relevance Score:** 0.596
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Robotic manipulation in unstructured environments requires reliable execution under diverse conditions, yet many state-of-the-art systems still struggle with high-dimensional action spaces, sparse rewards, and slow generalization beyond carefully curated training scenarios. We study these limitation...

[PDF](https://arxiv.org/pdf/2601.21394v1) | [arXiv](http://arxiv.org/abs/2601.21394v1)

---

## 8. [WheelArm-Sim: A Manipulation and Navigation Combined Multimodal Synthetic Data Generation Simulator for Unified Control in Assistive Robotics](http://arxiv.org/abs/2601.21129v1)

**Authors:** Guangping Liu, Tipu Sultan, Vittorio Di Giorgio, Nick Hawkins, Flavio Esposito, et al. (+1 more)

**Published:** 2026-01-29

**Categories:** cs.RO

**Relevance Score:** 0.590
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Wheelchairs and robotic arms enhance independent living by assisting individuals with upper-body and mobility limitations in their activities of daily living (ADLs). Although recent advancements in assistive robotics have focused on Wheelchair-Mounted Robotic Arms (WMRAs) and wheelchairs separately,...

[PDF](https://arxiv.org/pdf/2601.21129v1) | [arXiv](http://arxiv.org/abs/2601.21129v1)

---

## 9. [TaF-VLA: Tactile-Force Alignment in Vision-Language-Action Models for Force-aware Manipulation](http://arxiv.org/abs/2601.20321v2)

**Authors:** Yuzhe Huang, Pei Lin, Wanlin Li, Daohan Li, Jiajun Li, et al. (+3 more)

**Published:** 2026-01-28

**Categories:** cs.RO

**Relevance Score:** 0.579
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Vision-Language-Action (VLA) models have recently emerged as powerful generalists for robotic manipulation. However, due to their predominant reliance on visual modalities, they fundamentally lack the physical intuition required for contact-rich tasks that require precise force regulation and physic...

[PDF](https://arxiv.org/pdf/2601.20321v2) | [arXiv](http://arxiv.org/abs/2601.20321v2)

---

## 10. [CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation](http://arxiv.org/abs/2601.21712v1)

**Authors:** Xuanran Zhai, Binkai Ou, Yemin Wang, Hui Yi Leong, Qiaojun Yu, et al. (+2 more)

**Published:** 2026-01-29

**Categories:** cs.RO

**Relevance Score:** 0.579
 (Keyword matches: 1)

**Topic:** Robotics Manipulation

**Abstract:** Vision Language Action (VLA) models enable instruction following manipulation, yet dualarm deployment remains unsafe due to under modeled selfcollisions between arms and grasped objects. We introduce CoFreeVLA, which augments an endtoend VLA with a short horizon selfcollision risk estimator that pre...

[PDF](https://arxiv.org/pdf/2601.21712v1) | [arXiv](http://arxiv.org/abs/2601.21712v1)

---
